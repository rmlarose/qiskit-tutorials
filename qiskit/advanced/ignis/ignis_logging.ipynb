{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../../images/qiskit_header.png\" alt=\"Note: In order for images to show up in this jupyter notebook you need to select File => Trusted Notebook\" align=\"middle\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ignis Logging\n",
    "---\n",
    "\n",
    "* **Last Updated:** August 4, 2019\n",
    "* **Requires:** qiskit-ignis 0.2\n",
    "\n",
    "# Introduction\n",
    "\n",
    "This tutorial shows how to use logging in Ignis. The purpose of Ignis logging is twofold:\n",
    "1. Log run-time events and emit messages to the console.\n",
    "2. Log data of interest to a file. \n",
    "\n",
    "Ignis logging is based on [Python's logging package](https://docs.python.org/3/library/logging.html). There are 3 classes in the Ignis logging module: \n",
    "\n",
    "* **IgnisLogger** - Objects of this class are used for logging. The class is derived from the Logger class defined in the Python's logging package\n",
    "* **IgnisLogging** - A singleton class responsible for configuring logging behavior in Ignis as well as for creating  IgnisLogger objects\n",
    "* **IgnisLogReader** - A class for reading file logs created by IgnisLogger objects, containing filtering capabilities support\n",
    "\n",
    "\n",
    "## Using IgnisLogger\n",
    "\n",
    "In this section we will see how to log data to console and files using IgnisLogger objects\n",
    "\n",
    "### Creating a logger object\n",
    "Console and file logging in Ignis is performed using an object of the class IgnisLogger. Such an object is essentialy a Logger object of the [Python's logging package](https://docs.python.org/3/library/logging.html), extended with a convenient file logging capability. \n",
    "\n",
    "Let's create such an object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.ignis.logging import ignis_logging\n",
    "\n",
    "logger = ignis_logging.IgnisLogging().get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see here the use of the IgnisLogging singleton class for getting an IgnisLogger object. The parameter for the get_logger method gives the logger its name. This name is used when messages are printed to the console, to identify the source file which the log was printed from. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging to console\n",
    "\n",
    "Logging to console using an _IgnisLogger_ object is identical to using [Python's logging package](https://docs.python.org/3/library/logging.html). For convenience, here are some examples:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: __main__ - This is a warning\n",
      "ERROR: __main__ - An error message\n",
      "CRITICAL: __main__ - Critical error\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"An info message\") # wont show by default\n",
    "logger.warning(\"This is a warning\")\n",
    "logger.error(\"An error message\")\n",
    "logger.critical(\"Critical error\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuring console logging\n",
    "Essentially, console logging in Ignis is identical to python logging. For the most part, the important aspect to consider when using Python logging is message levels. There are 5 pre-defined message levels in Python logging, as listed below, in ascending order of severity:\n",
    "\n",
    "DEBUG <br>\n",
    "INFO <br>\n",
    "WARNING <br>\n",
    "ERROR <br>\n",
    "CRITICAL <br>\n",
    "\n",
    "The default message level in Python logging is WARNING, meaning all messages of WARNING severity or higher will be logged to the console. This is why the INFO message in the example above was not printed. You can set the severity level using the following code:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: __main__ - This will be printed now\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger.setLevel(logging.INFO)\n",
    "logger.info(\"This will be printed now\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For complete documantion on Python logging, see [here](https://docs.python.org/3/library/logging.html).\n",
    "\n",
    "### Logging to file\n",
    "\n",
    "Logging to file is carried out by using the log_to_file method of the _IgnisLogger_ class. The method expects key-value pairs given as Python keyword parameters. Any number of key-value pairs can be given to the method. Each call to the log_to_file method results in a new line being appended and stored in] the log file. Each line contains a timestamp, an identifying name and list of key-value pairs. Here are a few examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.log_to_file(t1=0.1, t2='0.3')\n",
    "logger.log_to_file(qubits=[0,1,3], fidelity=.9998)\n",
    "logger.log_to_file(dictionary={'a':1, 'b':2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is how these are logged in the log file:\n",
    "\n",
    "``\n",
    "2019/06/02 11:36:28 ignis_logging 't1':'0.1' 't2':'0.3' \n",
    "2019/06/02 11:36:28 ignis_logging 'qubits':'[0, 1, 3]' 'fidelity':'0.9998' \n",
    "2019/06/02 11:36:28 ignis_logging 'dictionary':'{'a': 1, 'b': 2}\n",
    "``\n",
    "\n",
    "Notice how the data is stored:\n",
    "Each key-value pair is seperated by ×©colon (:), the pairs are seperated by space and all keys and values are put in single qoutes ('). This makes it easy to import the data into a CSV or other regular data formats. \n",
    "\n",
    "### Configuring the IgnisLogger\n",
    "\n",
    "Besides creating _IgnisLogger_ objects, the _IgnisLogger_ class is used to configure the file logging aspects in Ignis.  The main aspects controlled by the _IgnisLogger_ class are:\n",
    "\n",
    "* Enabling/disabling file logging\n",
    "* Location of the log files\n",
    "* Miscellenous log file controls. \n",
    "\n",
    "The main vehicle for configuring Ignis logging is a configuration file, named *logging.yaml*, whose full path is expected by _IgnisLogger_ to be:\n",
    "\n",
    "``\n",
    "<USER HOME DIR>/.qiskit/logging.yaml\n",
    "``\n",
    "\n",
    "An example configuration file is located in the logging directory of Ignis. You can use this file as a starting point. \n",
    "\n",
    "The main settings in the configuration file are as follow:\n",
    "\n",
    "```yaml\n",
    "file_logging: true\t\t# Enables/disables file logging (true/false)\n",
    "log_file: ignis_test_log.log\t# Name of the file log\n",
    "max_size: 1000000\t\t# Max file size (in bytes). \n",
    "max_rotations: 5\t\t# Max number of file rotations\n",
    "```\n",
    "\n",
    "The max_size and max_rotations settings are used in conjuction with each other to limit the amount of disk space used for logging. Up to max_rotations files will be stored on disk, each of which is limited to max_size bytes in size, such that the most recent max_size * max_rotations bytes are stored in one or more log files. Rotated file names' are automatically sufixed with numbers. \n",
    "\n",
    "File logging can be enabled or disabled either by using the logging configuration file or by calling enable_file_logging or disable_file_logging methods of _IgnisLogger_, respectively. \n",
    "\n",
    "Note: File logging is disabled by default if no logging configuration file is provided. Enabling file logging without using a configuration file (i.e. programatically) results in _IgnisLogging_ using its internal file logging default settings.\n",
    "\n",
    "\n",
    "\n",
    "## IgnisLogReader\n",
    "The Ignis logging module comes with a log reader class called _IgnisLogReader_. The purpose of _IgnisLogReader_ is to retrieve log data from Ignis log files in such a way that it can be further processed and analysed. In essence, _IgnisLogReader_ returns a list of lists, each of which containing a list of key-value pairs. \n",
    "\n",
    "Note: since any data can be stored using _IgnisLogger_'s log_to_file method, it is up to the user to correctly interpret the logged data when using the _IgnisLogReader_ class. \n",
    "\n",
    "### Reading log data\n",
    "The most basic usage of the _IgnisLogReader_ is to retrieve all the data stored in the log file (or multiple files, in case of file rotations). Here is how this can be achieved: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019/06/02', '11:32:25', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:32:25', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:32:35', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:32:35', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:34:54', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:34:54', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:35:03', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:35:03', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:36:25', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:36:25', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:36:25', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n",
      "['2019/06/02', '11:36:28', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:36:28', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:36:28', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n",
      "['2019/06/02', '13:21:57', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '13:21:57', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '13:21:57', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n",
      "['2019/06/02', '14:12:24', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '14:12:24', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '14:12:24', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n",
      "['2019/06/02', '14:12:53', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '14:12:53', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '14:12:53', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n",
      "['2019/06/02', '14:14:56', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '14:14:56', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '14:14:56', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n"
     ]
    }
   ],
   "source": [
    "log_reader = ignis_logging.IgnisLogReader()\n",
    "rows = log_reader.read_values()\n",
    "print(*rows, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the data is retrieved as list of lists. In addition, when a logging configuration file is used, _IgnisLogReader_ will automatically read the log files as defined in the configuration file. You can specify a custom log file to read from using the log_file paramter of the read_values method.\n",
    "\n",
    "#### Filtering by date and time\n",
    "_IgnisFileReader_ supports date/time based filtering. You can specify a to and a from date/time, as well as a from-to range by combining both to and from datetime specifications. Here are a couple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019/06/02', '11:36:25', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:36:25', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:36:25', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n",
      "['2019/06/02', '11:36:28', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:36:28', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:36:28', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n",
      "['2019/06/02', '13:21:57', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '13:21:57', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '13:21:57', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n",
      "['2019/06/02', '14:12:24', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '14:12:24', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '14:12:24', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n",
      "['2019/06/02', '14:12:53', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '14:12:53', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '14:12:53', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n"
     ]
    }
   ],
   "source": [
    "rows = log_reader.read_values(from_datetime=\"2019/06/02 11:36:25\")\n",
    "print(*rows, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019/06/02', '11:36:25', \"'t1':'0.1'\", \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:36:25', \"'qubits':'[0,\", '1,', \"3]'\", \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:36:25', \"'dictionary':'{'a':\", '1,', \"'b':\", \"2}'\"]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "to_dt = datetime.strptime(\"02/06/19 11:36:25\", \"%d/%m/%y %H:%M:%S\")\n",
    "rows = log_reader.read_values(from_datetime=\"2019/06/02 11:36:25\", to_datetime=to_dt)\n",
    "print(*rows, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how the date/time parametrs can handle both date/time strings as well as datetime objects. \n",
    "#### Filtering by key names\n",
    "You can also ask _IgnisLogReader_ to retrieve only key-values pairs of specify keys. Use the _keys_ parameter of the read_values method to achieve that. For example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019/06/02', '11:32:25', \"'t1':'0.1'\"]\n",
      "['2019/06/02', '11:32:35', \"'t1':'0.1'\"]\n",
      "['2019/06/02', '11:34:54', \"'t1':'0.1'\"]\n",
      "['2019/06/02', '11:35:03', \"'t1':'0.1'\"]\n",
      "['2019/06/02', '11:36:25', \"'t1':'0.1'\"]\n",
      "['2019/06/02', '11:36:28', \"'t1':'0.1'\"]\n",
      "['2019/06/02', '13:21:57', \"'t1':'0.1'\"]\n",
      "['2019/06/02', '14:12:24', \"'t1':'0.1'\"]\n",
      "['2019/06/02', '14:12:53', \"'t1':'0.1'\"]\n"
     ]
    }
   ],
   "source": [
    "rows = log_reader.read_values(keys=\"t1\")\n",
    "print(*rows, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2019/06/02', '11:32:25', \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:32:25', \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:32:35', \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:32:35', \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:34:54', \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:34:54', \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:35:03', \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:35:03', \"'fidelity':'0.9998'\"]\n",
      "['2019/06/02', '11:36:25', \"'t2':'0.3'\"]\n",
      "['2019/06/02', '11:36:25', \"'fidelity':'0.9998'\"]\n"
     ]
    }
   ],
   "source": [
    "rows = log_reader.read_values(keys=[\"t2\", \"fidelity\"], to_datetime=to_dt)\n",
    "print(*rows, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once retrieved you can convert the data into a csv object, pandas or any other format for further processing and visualiztion. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
